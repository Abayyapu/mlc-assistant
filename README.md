<div align="center">
<img alt="image" src="./docs/webllm-assistant.png" style="margin-bottom: 20px;" />

<a href="https://github.com/mlc-ai/web-llm"><img alt="Related Repository: WebLLM" src="https://img.shields.io/badge/Related_Repo-WebLLM-fafbfc?logo=github"></a>
<a href="https://discord.gg/9Xpy2HGBuD"><img alt="Join Discord" src="https://img.shields.io/badge/Join-Discord-7289DA?logo=discord&logoColor=white"></a>

</div>

Chat with AI assistant running locally in your browser powered by WebGPU. This project is currently under development and supports document editing assistance on Overleaf. More features are planned.

![demo](https://github.com/mlc-ai/mlc-assistant/assets/11940172/51f0668d-860e-4014-b104-4d2e0e7b334e)

## Getting Started

### 1. Install Dependencies

Using your preferred JavaScript package manager to install the dependencies.

```bash
npm install
# or
yarn
# or
pnpm install
```

### 2. Build the Project

```bash
npm run build
# or
yarn build
# or
pnpm run build
```

### 3. Install the Chrome extension <a id='step6'></a>

Launch Google Chrome and navigate to the extensions page by entering `chrome://extensions`. Enable Developer Mode by clicking the toggle switch next to Developer mode. Click the Load unpacked button and select the `dist` directory.

<img src="https://github.com/mlc-ai/mlc-assistant/assets/11940172/cdb18fb3-24c5-41bf-9a40-484692c2150a" width="300">

## Links

- You might want to check out our online public [Machine Learning Compilation course](https://mlc.ai) for a systematic
  walkthrough of our approaches.
- [WebLLM](https://webllm.mlc.ai/) is a companion project using MLC LLM's WebGPU and WebAssembly backend.
- [WebStableDiffusion](https://websd.mlc.ai/) is a companion project for diffusion models with the WebGPU backend.
- Icons from [FlatIcon](https://www.flaticon.com/)
